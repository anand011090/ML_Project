{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 2 ..., 4 4 4]\n",
      "(38973, 15)\n",
      "(38973, 1)\n",
      "(15, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from numpy.linalg import inv\n",
    "import sys\n",
    "from numpy import *\n",
    "\n",
    "def sigmoid(arr): \n",
    "    new_arr=[]\n",
    "    cc=0;\n",
    "    for x in arr:\n",
    "        temp_sig = 1 / (1 + np.exp(-1*(x)));\n",
    "        new_arr.append(temp_sig);\n",
    "    return new_arr;\n",
    "\n",
    "def getTrainData():\n",
    "    data_df = pandas.read_csv('train.csv')\n",
    "    total_rows, total_cols = data_df.shape\n",
    "    allData = data_df.as_matrix()\n",
    "    noOfColumns = total_cols;\n",
    "    allData = allData[:, 1:noOfColumns];\n",
    "    cols,rows = allData.shape;\n",
    "    X = allData[:, 0:rows-1];\n",
    "    \n",
    "    a_1 = np.array(X.T[1])\n",
    "    dummy_1 = pandas.get_dummies(a_1)\n",
    "    X.T[1] = dummy_1.values.argmax(1)\n",
    "    print(X.T[1]);\n",
    "    a_2 = np.array(X.T[3])\n",
    "    dummy_2 = pandas.get_dummies(a_2)\n",
    "    X.T[3] = dummy_2.values.argmax(1)\n",
    "    a_3 = np.array(X.T[5])\n",
    "    dummy_3 = pandas.get_dummies(a_3)\n",
    "    X.T[5] = dummy_3.values.argmax(1)\n",
    "    a_4 = np.array(X.T[6])\n",
    "    dummy_4 = pandas.get_dummies(a_4)\n",
    "    X.T[6] = dummy_4.values.argmax(1)\n",
    "    a_5 = np.array(X.T[7])\n",
    "    dummy_5 = pandas.get_dummies(a_5)\n",
    "    X.T[7] = dummy_5.values.argmax(1)\n",
    "    a_6 = np.array(X.T[8])\n",
    "    dummy_6 = pandas.get_dummies(a_6)\n",
    "    X.T[8] = dummy_6.values.argmax(1)\n",
    "    a_7 = np.array(X.T[9])\n",
    "    dummy_7 = pandas.get_dummies(a_7)\n",
    "    X.T[9] = dummy_7.values.argmax(1)\n",
    "    a_8 = np.array(X.T[13])\n",
    "    dummy_8 = pandas.get_dummies(a_8)\n",
    "    X.T[13] = dummy_8.values.argmax(1)\n",
    "\n",
    "    Y = allData[:, rows-1:noOfColumns-1];\n",
    "    return X,Y;\n",
    "\n",
    "def feature_normalize(X):\n",
    "    #X = (X-mean(X,axis=0))/std(X,axis=0)\n",
    "    X = X / X.max(axis=0)\n",
    "    return X;\n",
    "\n",
    "X,Y = getTrainData();\n",
    "examples,features = X.shape;\n",
    "X = feature_normalize(X);\n",
    "X = np.insert(X,0,1,axis = 1)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "W_layer_1 = np.random.uniform(size=(features, 1))\n",
    "W_layer_1 = np.insert(W_layer_1,0,1,axis = 0)\n",
    "W_layer_2 = np.random.uniform(size=(features, 1))\n",
    "W_layer_2 = np.insert(W_layer_2,0,1,axis = 0)\n",
    "W_layer_3 = np.random.uniform(size=(features, 1))\n",
    "W_layer_3 = np.insert(W_layer_3,0,1,axis = 0)\n",
    "print(W_layer_1.shape)\n",
    "#err_1 = np.array(sigmoid(sum_1));\n",
    "#After getting all the data, working out with the weight vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,) (15, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X[0].shape,W_layer_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-820d720bc07a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mlayer1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_input_to_hidden1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlayer2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_hidden1_to_hidden2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlayer3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_hidden2_to_hidden3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layer0' is not defined"
     ]
    }
   ],
   "source": [
    "total_iterations = 1;\n",
    "exam = 1;\n",
    "for iter in range(total_iterations):\n",
    "    for index in range(exam):\n",
    "        layer1=sigmoid(np.dot(layer0, weights_input_to_hidden1));\n",
    "        layer2=sigmoid(np.dot(layer1, weights_hidden1_to_hidden2));\n",
    "        layer3 = sigmoid(np.dot(layer2, weights_hidden2_to_hidden3));\n",
    "        output=sigmoid(np.dot(layer3, weights_hidden3_to_output));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numberOfTrainingExamples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-422ce05be0ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m#training algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumberOfTrainingExamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[1;31m#print(\"iteration:- \" + str(iter) + \"Traingin example:- \" + str(index))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[1;31m#get section of input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numberOfTrainingExamples' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#numberOfTrainingExamples=100;\n",
    "\n",
    "#training algorithm\n",
    "for iter in range(1000):\n",
    "    for index in range(numberOfTrainingExamples):\n",
    "        #print(\"iteration:- \" + str(iter) + \"Traingin example:- \" + str(index))\n",
    "        #get section of input\n",
    "        trainingFeatures           = np.array([X[index].tolist()]);\n",
    "        trainingResponse           = np.array([y[index].tolist()]);\n",
    "        multiClassTrainingResponse = np.array([Y[index].tolist()]);\n",
    "\n",
    "        #feed forward the input to next layers\n",
    "        layer0=trainingFeatures;\n",
    "        layer1=sigmoid(np.dot(layer0, weights_input_to_hidden1));\n",
    "        layer2=sigmoid(np.dot(layer1, weights_hidden1_to_hidden2));\n",
    "        layer3 = sigmoid(np.dot(layer2, weights_hidden2_to_hidden3));\n",
    "        output=sigmoid(np.dot(layer3, weights_hidden3_to_output));\n",
    "        #print(\"output is \" + str(output));\n",
    "        #print(\"==================================\");\n",
    "        #print(\"actual shouuld be \" + str(multiClassTrainingResponse));\n",
    "        #next task is learn errors and back propage them and then recompute w's\n",
    "        #once learnt write function to find predicted class and see if it works\n",
    "\n",
    "        #error computation\t\t\n",
    "        outputLayerError         = output - multiClassTrainingResponse ;\n",
    "        #print(\"error values are:- \" + str(outputLayerError));\n",
    "        #print(\"printed sum is \" + str(np.sum(np.abs(outputLayerError))));\n",
    "        outputLayerErrorStrength = outputLayerError*derivative_to_sigmoid(output);\n",
    "        layer3Error              = outputLayerErrorStrength.dot(weights_hidden3_to_output.T);\n",
    "        layer3ErrorStrength      = layer3Error*derivative_to_sigmoid(layer3);\n",
    "        layer2Error              = layer3ErrorStrength.dot(weights_hidden2_to_hidden3.T);\n",
    "        layer2ErrorStrength      = layer2Error*derivative_to_sigmoid(layer2);\t\t\n",
    "        layer1Error              = layer2ErrorStrength.dot(weights_hidden1_to_hidden2.T);\n",
    "        layer1ErrorStrength      = layer1Error*derivative_to_sigmoid(layer1);\n",
    "        weights_output_update = layer3.T.dot(outputLayerErrorStrength);\n",
    "        weights_layer3_update = layer2.T.dot(layer3ErrorStrength);\n",
    "        weights_layer2_update = layer1.T.dot(layer2ErrorStrength);\n",
    "        weights_layer1_update = layer0.T.dot(layer1ErrorStrength);\n",
    "\n",
    "        weights_input_to_hidden1-=alpha*weights_layer1_update;\n",
    "        weights_hidden1_to_hidden2-=alpha*weights_layer2_update;\n",
    "        weights_hidden2_to_hidden3-=alpha*weights_layer3_update;\n",
    "        weights_hidden3_to_output-=alpha*weights_output_update;\n",
    "    xx = trainData[:numberOfTrainingExamples, feature_cols]\n",
    "    yy = np.array(trainData[:numberOfTrainingExamples, response_cols])\n",
    "    yy2 = getMultiClassResponse(yy, numberOfClasses);\n",
    "    l00 = xx;\n",
    "    l11 = sigmoid(np.dot(l00, weights_input_to_hidden1));\n",
    "    l22 = sigmoid(np.dot(l11, weights_hidden1_to_hidden2));\n",
    "    l33 = sigmoid(np.dot(l22, weights_hidden2_to_hidden3));\n",
    "    l44 = sigmoid(np.dot(l33, weights_hidden3_to_output));\n",
    "    myError = l44-yy2;\n",
    "    print(\"Printing error:- \" + str(np.sum(np.abs(myError))));\n",
    "    #print(\"weights input to hidden1 are:- \" + str(weights_input_to_hidden1));\n",
    "    #print(\"hidden1 to hidden2 are:- \" + str(weights_hidden1_to_hidden2));\n",
    "    #print(\"hidden2 to output layer weights are:- \" + str(weights_hidden2_to_output));\n",
    "    predictions = makePredictions(l44, numberOfTrainingExamples);\n",
    "        #print(\"predictions shape is \" + str(predictions));\n",
    "        #print(\"actual shape is \" + str(yy.shape));\n",
    "        #print(\"y actually is \" + str(yy));\n",
    "        #print(\"listed y is \" + str(yy.ravel()));\n",
    "    yy=yy.ravel();\t\n",
    "    print(\"iteration number is \" + str(iter));\t\n",
    "    numMisclassified = getErrorCount(yy, predictions);\n",
    "    stringToLog = \"iteration number is \"+str(iter)+ \" error:- \" + str(np.sum(np.abs(myError))) + \" misclassified \" + str(numMisclassified);\n",
    "    with open(\"./myOutputs/logs.txt\", \"a\") as myfile:\n",
    "        myfile.write(stringToLog + \"\\n\")\t\n",
    "    l0 = testX;\n",
    "    l1 = sigmoid(np.dot(l0, weights_input_to_hidden1));\n",
    "    l2 = sigmoid(np.dot(l1, weights_hidden1_to_hidden2));\n",
    "    l3 = sigmoid(np.dot(l2, weights_hidden2_to_hidden3));\n",
    "    l4 = sigmoid(np.dot(l3, weights_hidden3_to_output));\t\n",
    "    numberOfTestingExamples=testX.shape[0];\n",
    "    predictions = makePredictions(l4, numberOfTestingExamples);\n",
    "    name=['CLASS']\n",
    "    testResponseDataFrame = pd.DataFrame(predictions, columns=name)\n",
    "    result = testDataInCsv.join(testResponseDataFrame)\n",
    "    testResponseDataFrame.index.names = ['id']\n",
    "    outputName=\"./myOutputs/output\"+str(iter)+\".csv\"\n",
    "    testResponseDataFrame.to_csv(outputName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
